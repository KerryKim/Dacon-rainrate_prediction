★ Image Classification Pipe-line Strategy

※ 기본원칙
- 각 단계를 거치면서 모델은 단순한 것에서 시작하여 점차 복잡한 것으로 발달시킨다.
- 매 단계에서 어떠한 일이 생기지에 대한 구체적인 가설을 세우며, 도입 후 혹시 발생했을지 모를 문제를 찾아내기 위해 실험과 검증을 반복한다.

1. Training Data Observing & Preprocessing
   - Data Analysis (ex> heat map, graph, ...)
	1. 데이터 중복 체크
	2. 손상된 이미지 (노이즈), 라벨 체크 (데이터의 비정상적인 변화 체크)
	3. 데이터 불균형, 편향 체크
	4. 데이터의 지역적인 특성들 만으로 충분한지 혹은 전체적인 맥락이 필요한지 (feature importance)
	5. 데이터의 공간적 위치가 중요한지
	6. Average 풀링이 좋을지
	7. 많은 이미지를 샘플링을 통해 얼마나 줄일지


2. Building Baseline model
   - 절대 망치기 힘든 단순한 모델을 기반으로 baseline 구현 (ex> 아주 작은 conv net 또는 선형 분류기 등)
	* 1단계 (기초 다지기)
	1. 랜덤 시드를 고정시켜라 (항상 같은 결과를 얻을 수 있다.)
	2. 데이터 증강을 절대 하지 말고 단순화 시켜라
	3. 인간 능력을 모델의 기준 목표값으로 삼아라 (bayes optimal score)
	4. 한 배치만 레이어나 필터를 더해서 용량을 키운 후 과적합 시켜보기 => 즉 데이터를 샘플링해서 작은 데이터로 과적합시켜보며 0에 가까운 loss에 도달할 수 있는지 확인해 본다.
	5. 입력과 독립적인 기준값 => 모든 입력을 0으로 주어서 진짜 데이터를 넣었을 때보다 성능이 떨어지는지 확인
	
	* 2단계 (기초 다시 다지기) 
	6. Loss가 정상적으로 감소하는지 확인 => 지금까진 작은 모델을 사용했기 때문에 과소적합이다. 모델 용량을 아주 조금 증가시켜보고 loss가 정상적으로 감소하는지 확인.
	7. 모델에 넣기 바로 전단계에서 데이터 시각화 시도

	* 3단계 (과적합으로 모델 성능 끌어올리기)
	8. 과적합에 용이한 큰 모델을 학습시키면서 학습 손실값을 최소화하는데 집중하기
	   - 영웅이 되려하지 말고 가장 단순하면서 성능이 좋은 아키텍쳐 선정
	   - Optimizer로 Adam 사용해라. 대부분의 경우 Conv net에서 튜닝이 잘된 SGD를 제외하면 아담이 제일 낫다.
	   - 새로운 시도(복잡도)는 한 번에 한 번씩만 더해라 => Cross validation, SWA, Residual Learning, 다른 활성화함수 적용 등
	   - Learning rate decay는 같은 값을 다른 코드에 가져다 쓸 수 없다 (학습을 시킬 때 decay를 일단 끄고 가장 마지막에 튜닝 추천)

	* 4단계 (일반화로 모델 성능 끌어올리기) => 학습 정확도(또는 training loss)가 낮아지더라도 테스트 정확도를 향상 시켜보자.
	9. 데이터 전처리 (Normalization (ex> 1/224, standaradscalar(정규분포), minmaxscalar(비정규분포))) => 전처리를 할 때 평균-표준편차의 통계값은 훈련 데이터에서 얻은 통계값을 사용해야 한다. (data leakage, Normalization 참고)
	10. 더 많은 데이터를 모아라 => 앙상블은 다섯개 정도의 모델 이후로는 성능이 증가하지 않는다.
	11. Data augmentation (cutmix, resize, rotate, transpose, flip, sudo labeling)
	12. 전이학습 시도
	13. 입력 차원은 낮게(단순하게) 해라 => 미심쩍은 시그널을 포함한 피처를 제거해라. 작은 피쳐의 데이터 사이즈가 작으면 과적합의 빌미가 된다. 이미지의 세세한 디테일이 중요하지 않다면 작은 이미지를 사용.
	14. 모델 크기를 작게 해라 => Fully connected layer에서 average plooling이 대세가 되었다.
	15. 배치 크기를 줄여보자 => 배치정규화 안의 정규화때문에 작은 배치사이즈가 더 강한 일반화를 이끌어 낸다.
	16. 드롭아웃 추가 => ConvNet은 Dropout2d 사용. dropout은 배치정규화와 잘 어울리지 못하는 경우도 있으므로 주의.
	17. Learning rate decay 사용
	18. Early stopping 사용
	19. 더 큰 모델을 시도 => early stopping으로 큰 모델이 과적합하기 전에 미리 멈춘 모델은 작은 모델보다 성능이 좋다.
	
	* 5단계 (마지막 한 방울까지)
	19. 하이퍼파라미터 튜닝 => 무작위 튜닝
	  - 학습률 선정 : Local optimum에 빠지지 않기위해 학습률을 변화시키면서 학습시켜보는 것이 중요
		        3e-4, 1e-4 (0.0001), 3e-5, 1e-5 와 같이 3배로 줄이거나 늘이고 어느정도 정확도가 잘나오는 lr을 찾으면 
                                그 주변에서 값을 조금씩 변화시켜 찾는것을 추천
	  - 모멘텀, 베타
	  - 히든 유닛 수 : 얼마나 많은 filter를 사용할 것인지
	  - 배치 사이즈 : 배치사이즈가 작은 경우 입력 피처가 작고 다양해서 loss값이 이리저리 튄다.
	  	         최적의 배치사이즈는 데이터에 따라 다르다. 전체 데이터셋 학습은 deterministc, 배치학습은 stochastic.
		         주어진 데이터에선 전체 데이터셋 학습이 유리할 수도 있지만 테스트 데이터에선 stochastic이 더 유리할 수도 있다.
		         (배치 사이즈가 작으면 클때 학습하지 못하는 부분을 학습할 수 도 있다. 일반적으로 이미지는 32?)
		         배치사이즈가 극단적으로 커지면 error 커진다.
	  - 에폭 :  에폭의 크기는 validation과 train의 metric이 똑같이 지속적으로 감소하는 구간까지로 정함. 
	
	20. 앙상블 시도
	21. 계속 학습시키기 => loss가 줄어들지 않아도 계속 학습시켜 볼 만하다.

  - 마지막으로 분류기가 잘 작동하는지 확인하기 위해 네트워크의 첫 번째 레이어의 가중치 값을 시각화하여 깔끔한 모서리가 나오는지 확인하자. 이것이 문제에 대한 힌트를 줄 수도 있다.


https://medium.com/@bntejn/%EC%9D%B8%EA%B3%B5%EC%8B%A0%EA%B2%BD%EB%A7%9D-%ED%95%99%EC%8A%B5-%EB%A0%88%EC%8B%9C%ED%94%BC-%EB%B2%88%EC%97%AD-70c5e58341ec